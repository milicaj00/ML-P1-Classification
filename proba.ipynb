{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "data1 = pd.read_csv(\"data.csv\")\n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Number Of Rows In The Original DataFrame:\", len(data))\n",
    "print(\"Number Of Rows After Deduping:\", len(data.drop_duplicates()))\n",
    "\n",
    "'''\n",
    "Diagnosis - specific combination of ICD-10 codes for primary and secondary as well multiple tumours if any\t\t\n",
    "PRE4\tFeature\tContinuous\t\tForced vital capacity - FVC (numeric)\t\n",
    "PRE5\tFeature\tContinuous\t\tVolume that has been exhaled at the end of the first second of forced expiration - FEV1 (numeric)\t\t\n",
    "PRE6\tFeature\tCategorical\t\tPerformance status - Zubrod scale (PRZ2,PRZ1,PRZ0)\t\t\n",
    "PRE7\tFeature\tBinary\t\tPain before surgery (T,F)\t\n",
    "PRE8\tFeature\tBinary\t\tHaemoptysis before surgery (T,F)\t\t\n",
    "PRE9\tFeature\tBinary\t\tDyspnoea before surgery (T,F)\t\t\n",
    "PRE10\tFeature\tBinary\t\tCough before surgery (T,F)\t\n",
    "PRE11\tFeature\tBinary\t\tWeakness before surgery (T,F)\t\n",
    "PRE14\tFeature\tCategorical\t\tT in clinical TNM - size of the original tumour, from OC11 (smallest) to OC14 (largest) (OC11,OC14,OC12,OC13)\t\n",
    "PRE17\tFeature\tBinary\t\tType 2 DM - diabetes mellitus (T,F)\t\tno\n",
    "PRE19\tFeature\tBinary\t\tMI up to 6 months (T,F)\t\tno\n",
    "PRE25\tFeature\tBinary\t\tPAD - peripheral arterial diseases (T,F)\t\tno\n",
    "PRE30\tFeature\tBinary\t\tSmoking (T,F)\t\tno\n",
    "PRE32\tFeature\tBinary\t\tAsthma (T,F)\t\tno\n",
    "AGE\tFeature\tInteger\tAge\tAge at surgery (numeric)\t\tno\n",
    "Risk1Yr\tTarget\tBinary\t\t1 year survival period - (T)rue value if died (T,F)\t\tno\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include = \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dgn = data['DGN']\n",
    "pre6 = data['PRE6']\n",
    "pre14 = data['PRE14']\n",
    "\n",
    "pyplot.figure()\n",
    "pyplot.subplot(311);pyplot.xlabel('dgn'); pyplot.hist(dgn)\n",
    "pyplot.subplot(312); pyplot.xlabel('pre6'); pyplot.hist(pre6) \n",
    "pyplot.subplot(313);pyplot.xlabel('pre14'); pyplot.hist(pre14) \n",
    "# pyplot.show()\n",
    "\n",
    "age = data['AGE']\n",
    "pyplot.xlabel('age'); pyplot.hist(age) ; pyplot.show()\n",
    "\n",
    "pre4 = data['PRE4']\n",
    "pyplot.xlabel('Forced vital capacity - FVC'); pyplot.hist(pre4);pyplot.show()\n",
    "\n",
    "pre5 = data['PRE5']\n",
    "pyplot.xlabel('Volume that has been exhaled at the end of the first second of forced expiration'); pyplot.hist(pre5); pyplot.show()\n",
    "\n",
    "pre7 = data['PRE7']\n",
    "pre8 = data['PRE8']\n",
    "pre9 = data['PRE9']\n",
    "pre10 = data['PRE10']\n",
    "\n",
    "pyplot.figure()\n",
    "pyplot.subplot(221); pyplot.xlabel('pre10'); pyplot.hist(pre10) \n",
    "pyplot.subplot(222);pyplot.xlabel('pre7'); pyplot.hist(pre7)\n",
    "pyplot.subplot(223); pyplot.xlabel('pre8'); pyplot.hist(pre8) \n",
    "pyplot.subplot(224);pyplot.xlabel('pre9'); pyplot.hist(pre9)\n",
    "# pyplot.show()\n",
    "\n",
    "\n",
    "pre11 = data['PRE11']\n",
    "pre17 = data['PRE17']\n",
    "pre19 = data['PRE19']\n",
    "\n",
    "pyplot.figure()\n",
    "pyplot.subplot(311);pyplot.xlabel('pre11'); pyplot.hist(pre11)\n",
    "pyplot.subplot(312); pyplot.xlabel('pre17'); pyplot.hist(pre17) \n",
    "pyplot.subplot(313);pyplot.xlabel('pre19'); pyplot.hist(pre19)\n",
    "pyplot.show()\n",
    "\n",
    "pre25 = data['PRE25']\n",
    "pre30 = data['PRE30']\n",
    "pre32 = data['PRE32']\n",
    "\n",
    "pyplot.figure()\n",
    "pyplot.subplot(311);pyplot.ylabel('pre25'); pyplot.hist(pre25)\n",
    "pyplot.subplot(312);pyplot.ylabel('pre30'); pyplot.hist(pre30)\n",
    "pyplot.subplot(313);pyplot.ylabel('pre32'); pyplot.hist(pre32)\n",
    "pyplot.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data.columns[:-2]:\n",
    "    pyplot.figure(figsize=(5, 3))\n",
    "    sns.histplot(data[column], kde=True)\n",
    "    pyplot.title(f'Distribution of {column}')\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = data1.loc[data1['PRE25'] == 'T', 'Risk1Yr']\n",
    "\n",
    "filtered_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1 = data1.drop(columns=['PRE32', 'PRE19', 'PRE25'])\n",
    "# data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['PRE7', 'PRE8', 'PRE9', 'PRE10', 'PRE11', 'PRE17','PRE30','Risk1Yr','PRE32', 'PRE19', 'PRE25']\n",
    "data2 = pd.get_dummies(data=data1, columns=['DGN'], dtype=int)\n",
    "\n",
    "data2 = pd.get_dummies(data=data2, columns=labels, dtype=int, drop_first=True)\n",
    "\n",
    "# Create mapper\n",
    "scale_mapper = {'OC11':1,\n",
    " 'OC12':2,\n",
    " 'OC13':3,\n",
    " 'OC14':4 }\n",
    "\n",
    "data2[\"PRE14\"] = data2[\"PRE14\"].replace(scale_mapper)\n",
    "\n",
    "scale_mapper2 = {'PRZ0':1,\n",
    " 'PRZ1':2,\n",
    " 'PRZ2':3}\n",
    "\n",
    "data2[\"PRE6\"] = data2[\"PRE6\"].replace(scale_mapper2)\n",
    "data2.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = data2.corr()\n",
    "fig, ax = pyplot.subplots(figsize = (17,17))\n",
    "sns.heatmap(data=df_corr, annot=True, ax=ax, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sve kolone koje nisu konacne\n",
    "cols = [col for col in data2.columns if col not in ['Risk1Yr_T']]\n",
    "data_features = data2[cols]\n",
    "target = data2['Risk1Yr_T']\n",
    "data_features.head(2)\n",
    "\n",
    "# Standardize features\n",
    "standardizer = StandardScaler()\n",
    "data_features =  standardizer.fit_transform(data_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = {\n",
    "    'knn': {\n",
    "        'basic':0,\n",
    "        'cross':0,\n",
    "        'balanced':0\n",
    "    },\n",
    "    'random forest': {\n",
    "        'basic':0,\n",
    "        'cross':0,\n",
    "        'balanced':0\n",
    "    },\n",
    "    'Logistic Regression':{\n",
    "        'basic':0,\n",
    "        'cross':0,\n",
    "        'balanced':0\n",
    "    },\n",
    "    \"LinearSVC\":{\n",
    "        'basic':0,\n",
    "        'cross':0,\n",
    "        'balanced':0\n",
    "    },\n",
    "    \"BernoulliNB\":{\n",
    "        'basic':0,\n",
    "        'cross':0,\n",
    "        'balanced':0\n",
    "    },\n",
    "    'GaussianNB':{\n",
    "        'basic':0,\n",
    "        'cross':0,\n",
    "        'balanced':0\n",
    "    },\n",
    "    'DecisionTree':{\n",
    "        'basic':0,\n",
    "        'cross':0,\n",
    "        'balanced':0\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_train,data_test,target_train,target_test = train_test_split(data_features,target,test_size=0.2,random_state=47)\n",
    "\n",
    "print(f\"Broj uzoraka u trening skupu podataka: {len(data_train)}\")\n",
    "print(f\"Broj uzoraka u test skupu podataka: {len(data_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "# Create classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "# Train model\n",
    "rf_model = rf_classifier.fit(data_train, target_train)\n",
    "rf_pred = rf_model.predict(data_test)\n",
    "# Get accuracy score\n",
    "res = accuracy_score(target_test, rf_pred, normalize = True)\n",
    "print(\" RandomForest accuracy : \", res)\n",
    "\n",
    "results['random forest']['basic'] = res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trazimo znacajne podatke\n",
    "importances = rf_model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "names = [data2.columns[i] for i in indices]\n",
    "\n",
    "pyplot.figure()\n",
    "\n",
    "pyplot.title(\"Feature Importance\")\n",
    "\n",
    "pyplot.bar(range(data_train.shape[1]), importances[indices])\n",
    "\n",
    "pyplot.xticks(range(data_train.shape[1]), names, rotation=90)\n",
    "\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "def selectFeaturesRF(th):\n",
    "    selector = SelectFromModel(rf_classifier, threshold=th) \n",
    "\n",
    "    features_important = selector.fit_transform(data_train, target_train)\n",
    "\n",
    "    test_important = selector.transform(data_test)\n",
    "\n",
    "    randomForestModel = rf_classifier.fit(features_important,target_train)\n",
    "\n",
    "    predRFC = randomForestModel.predict(test_important)\n",
    "    res = accuracy_score(target_test, predRFC, normalize = True)\n",
    "    print(\"RandomForest accuracy : \",res )\n",
    "    results['random forest']['importance'] = res\n",
    "\n",
    "selectFeaturesRF(0.032)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#dodati scaler\n",
    "nearest_neighbors = KNeighborsClassifier(n_neighbors=8)\n",
    "\n",
    "knn_model = nearest_neighbors.fit(data_train,target_train)\n",
    "\n",
    "predNN = knn_model.predict(data_test)\n",
    "\n",
    "res=nearest_neighbors.score(data_test, target_test)\n",
    "print(\"KNeighbors accuracy : \", res)\n",
    "\n",
    "results['knn']['basic'] = res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "logistic_regression = LogisticRegression(random_state=0)\n",
    "# Train model\n",
    "lr_model = logistic_regression.fit(data_train, target_train)\n",
    "\n",
    "pred_lr = lr_model.predict(data_test)\n",
    "\n",
    "print(\"Logistic Regression : \",accuracy_score(target_test, pred_lr, normalize = True))\n",
    "\n",
    "results['Logistic Regression']['basic'] = accuracy_score(target_test, pred_lr, normalize = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svc_model = LinearSVC( C=1.0, random_state=0,  dual='auto')\n",
    "\n",
    "pred = svc_model.fit(data_train, target_train).predict(data_test)\n",
    "\n",
    "print(\"LinearSVC accuracy : \",accuracy_score(target_test, pred, normalize = True))\n",
    "\n",
    "results['LinearSVC']['basic'] = accuracy_score(target_test, pred_lr, normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "nb_classifer = BernoulliNB()\n",
    "model = nb_classifer.fit(data_train, target_train).predict(data_test)\n",
    "\n",
    "print(\"BernoulliNB : \",accuracy_score(target_test, model, normalize = True))\n",
    "\n",
    "results['BernoulliNB']['basic'] = accuracy_score(target_test, model, normalize = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inicijalizacija i treniranje modela \n",
    "gnb_classifer = GaussianNB()\n",
    "gnb_classifer.fit(data_train, target_train)\n",
    "\n",
    "# Predikcija na test skupu\n",
    "pred = gnb_classifer.predict(data_test)\n",
    "\n",
    "# Evaluacija performansi modela\n",
    "print(\"GaussianNB() accuracy:  \", (accuracy_score(target_test, pred, normalize = True)))\n",
    "results['GaussianNB']['basic'] = accuracy_score(target_test, pred, normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decisionTree = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "predDT = decisionTree.fit(data_train, target_train).predict(data_test)\n",
    "\n",
    "print(\"DecisionTree accuracy : \", accuracy_score(target_test, predDT, normalize = True))\n",
    "\n",
    "results['DecisionTree']['basic'] = accuracy_score(target_test, predDT, normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "data_pre_smote = pd.DataFrame({'Class': target})\n",
    "class_counts_pre_smote = data_pre_smote['Class'].value_counts()\n",
    "\n",
    "pyplot.figure(figsize=(5, 3))\n",
    "pie_pre_smote = class_counts_pre_smote.plot(kind='pie', autopct='%1.0f%%')\n",
    "pie_pre_smote.figure.set_size_inches(5, 3)\n",
    "pie_pre_smote.figure.legend(loc='lower right')\n",
    "pyplot.title(\"Distribucija klasa pre SMOTE\")\n",
    "pyplot.show()\n",
    "\n",
    "sm = SMOTE(random_state=2)\n",
    "data_features_res, target_res = sm.fit_resample(data_features, target)\n",
    "\n",
    "data_post_smote = pd.DataFrame({'Class': target_res})\n",
    "class_counts_post_smote = data_post_smote['Class'].value_counts()\n",
    "\n",
    "pyplot.figure(figsize=(5, 3))\n",
    "pie_post_smote = class_counts_post_smote.plot(kind='pie', autopct='%1.0f%%')\n",
    "pie_post_smote.figure.set_size_inches(5, 3)\n",
    "pie_post_smote.figure.legend(loc='lower right')\n",
    "pyplot.title(\"Distribucija klasa posle SMOTE\")\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(data_features_res, target_res, test_size=0.2, random_state=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model.fit(data_train, target_train)\n",
    "# Predikcija na test skupu\n",
    "pred = svc_model.predict(data_test)\n",
    "# Evaluacija performansi modela\n",
    "print(\"LinearSVC accuracy after SMOTE:  \", (accuracy_score(target_test, pred)))\n",
    "\n",
    "\n",
    "rf_model.fit(data_train, target_train)\n",
    "rf_pred = rf_model.predict(data_test)\n",
    "print(\"random forest accuracy after SMOTE:  \", (accuracy_score(target_test, rf_pred)))\n",
    "\n",
    "knn_model.fit(data_train, target_train)\n",
    "predNN = rf_model.predict(data_test)\n",
    "print(\"knn accuracy after SMOTE:  \", (accuracy_score(target_test, predNN)))\n",
    "\n",
    "predDT = decisionTree.fit(data_train, target_train).predict(data_test)\n",
    "print(\"decision tree accuracy after SMOTE:  \", (accuracy_score(target_test, predDT)))\n",
    "\n",
    "\n",
    "BernoulliNB = nb_classifer.fit(data_train, target_train).predict(data_test)\n",
    "print(\"nb accuracy after SMOTE:  \", (accuracy_score(target_test, BernoulliNB)))\n",
    "\n",
    "lr_model = logistic_regression.fit(data_train, target_train)\n",
    "pred_lr = lr_model.predict(data_test)\n",
    "print(\"linear regression accuracy after SMOTE:  \", (accuracy_score(target_test, pred_lr)))\n",
    "\n",
    "results['LinearSVC']['balanced'] =accuracy_score(target_test, pred)\n",
    "results['random forest']['balanced'] =accuracy_score(target_test, rf_pred)\n",
    "results['knn']['balanced'] =accuracy_score(target_test, predNN)\n",
    "results['DecisionTree']['balanced'] =accuracy_score(target_test, predDT)\n",
    "results['BernoulliNB']['balanced'] =accuracy_score(target_test, BernoulliNB)\n",
    "results['Logistic Regression']['balanced'] =accuracy_score(target_test, pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kros-validacija\n",
    "cv_results = cross_validate(rf_model, data_features, target, cv=kfold, scoring='accuracy')\n",
    "print(\"Average Accuracy: \", np.mean(cv_results['test_score']))\n",
    "print(\"Random forest cross validation accuracy: \", cv_results['test_score'])\n",
    "results['random forest']['cross'] =  np.mean(cv_results['test_score'])\n",
    "\n",
    "\n",
    "cv_results = cross_validate(knn_model, data_features, target, cv=kfold, scoring='accuracy')\n",
    "print(\"Average Accuracy: \", np.mean(cv_results['test_score']))\n",
    "print(\"KNeighbors cross validation accuracy: \", cv_results['test_score'])\n",
    "results['knn']['cross'] =  np.mean(cv_results['test_score'])\n",
    "\n",
    "cv_results = cross_validate(logistic_regression, data_features, target, cv=kfold, scoring='accuracy')\n",
    "print(\"Average Accuracy: \", np.mean(cv_results['test_score']))\n",
    "print(\"LogisticRegression cross validation accuracy: \", cv_results['test_score'])\n",
    "results['Logistic Regression']['cross'] = np.mean(cv_results['test_score'])\n",
    "\n",
    "cv_results = cross_validate(svc_model, data_features, target, cv=kfold, scoring='accuracy')\n",
    "print(\"Average Accuracy: \", np.mean(cv_results['test_score']))\n",
    "print(\"LinearSVC cross validation accuracy: \", cv_results['test_score'])\n",
    "results['LinearSVC']['cross'] =  np.mean(cv_results['test_score'])\n",
    "\n",
    "\n",
    "cv_results = cross_validate(nb_classifer, data_features, target, cv=kfold, scoring='accuracy')\n",
    "print(\"Average Accuracy: \", np.mean(cv_results['test_score']))\n",
    "print(\"BernoulliNB cross validation accuracy: \", cv_results['test_score'])\n",
    "results['BernoulliNB']['cross'] = np.mean(cv_results['test_score'])\n",
    "\n",
    "\n",
    "cv_results = cross_validate(gnb_classifer, data_features, target, cv=kfold, scoring='accuracy')\n",
    "print(\"Average Accuracy: \", np.mean(cv_results['test_score']))\n",
    "print(\"GaussianNB cross validation accuracy: \", cv_results['test_score'])\n",
    "results['GaussianNB']['cross'] = np.mean(cv_results['test_score'])\n",
    "\n",
    "cv_results = cross_validate(decisionTree, data_features, target, cv=kfold, scoring='accuracy')\n",
    "print(\"Average Accuracy: \", np.mean(cv_results['test_score']))\n",
    "print(\"DecisionTree cross validation accuracy: \", cv_results['test_score'])\n",
    "results['DecisionTree']['cross'] = np.mean(cv_results['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>knn</th>\n",
       "      <th>random forest</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>LinearSVC</th>\n",
       "      <th>BernoulliNB</th>\n",
       "      <th>GaussianNB</th>\n",
       "      <th>DecisionTree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>basic</th>\n",
       "      <td>0.797872</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.797872</td>\n",
       "      <td>0.202128</td>\n",
       "      <td>0.712766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cross</th>\n",
       "      <td>0.838298</td>\n",
       "      <td>0.846809</td>\n",
       "      <td>0.831915</td>\n",
       "      <td>0.838298</td>\n",
       "      <td>0.834043</td>\n",
       "      <td>0.159574</td>\n",
       "      <td>0.768085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced</th>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.837500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>importance</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776596</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 knn  random forest  Logistic Regression  LinearSVC  \\\n",
       "basic       0.797872       0.808511             0.808511   0.808511   \n",
       "cross       0.838298       0.846809             0.831915   0.838298   \n",
       "balanced    0.912500       0.912500             0.725000   0.718750   \n",
       "importance       NaN       0.776596                  NaN        NaN   \n",
       "\n",
       "            BernoulliNB  GaussianNB  DecisionTree  \n",
       "basic          0.797872    0.202128      0.712766  \n",
       "cross          0.834043    0.159574      0.768085  \n",
       "balanced       0.675000    0.000000      0.837500  \n",
       "importance          NaN         NaN           NaN  "
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
